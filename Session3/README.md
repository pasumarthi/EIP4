
###Final Validation with bsae network
Epoch 1/50
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.

390/390 [==============================] - 30s 77ms/step - loss: 1.8476 - acc: 0.2937 - val_loss: 1.4325 - val_acc: 0.4768
Epoch 2/50
390/390 [==============================] - 21s 53ms/step - loss: 1.3456 - acc: 0.5138 - val_loss: 1.1187 - val_acc: 0.5972
Epoch 3/50
390/390 [==============================] - 21s 53ms/step - loss: 1.1214 - acc: 0.6008 - val_loss: 0.9869 - val_acc: 0.6465
Epoch 4/50
390/390 [==============================] - 21s 53ms/step - loss: 0.9936 - acc: 0.6555 - val_loss: 0.9031 - val_acc: 0.6873
Epoch 5/50
390/390 [==============================] - 21s 53ms/step - loss: 0.9049 - acc: 0.6854 - val_loss: 0.9309 - val_acc: 0.6869
Epoch 6/50
390/390 [==============================] - 21s 53ms/step - loss: 0.8375 - acc: 0.7128 - val_loss: 0.7729 - val_acc: 0.7340
Epoch 7/50
390/390 [==============================] - 21s 53ms/step - loss: 0.7756 - acc: 0.7357 - val_loss: 0.7137 - val_acc: 0.7525
Epoch 8/50
390/390 [==============================] - 21s 53ms/step - loss: 0.7258 - acc: 0.7518 - val_loss: 0.6721 - val_acc: 0.7744
Epoch 9/50
390/390 [==============================] - 21s 53ms/step - loss: 0.6801 - acc: 0.7657 - val_loss: 0.6814 - val_acc: 0.7630
Epoch 10/50
390/390 [==============================] - 21s 53ms/step - loss: 0.6608 - acc: 0.7765 - val_loss: 0.6604 - val_acc: 0.7777
Epoch 11/50
390/390 [==============================] - 21s 53ms/step - loss: 0.6229 - acc: 0.7876 - val_loss: 0.6277 - val_acc: 0.7878
Epoch 12/50
390/390 [==============================] - 21s 53ms/step - loss: 0.6007 - acc: 0.7972 - val_loss: 0.6264 - val_acc: 0.7909
Epoch 13/50
390/390 [==============================] - 21s 53ms/step - loss: 0.5811 - acc: 0.8035 - val_loss: 0.6118 - val_acc: 0.7924
Epoch 14/50
390/390 [==============================] - 20s 52ms/step - loss: 0.5501 - acc: 0.8110 - val_loss: 0.6056 - val_acc: 0.7955
Epoch 15/50
390/390 [==============================] - 21s 53ms/step - loss: 0.5495 - acc: 0.8131 - val_loss: 0.6088 - val_acc: 0.7956
Epoch 16/50
390/390 [==============================] - 21s 53ms/step - loss: 0.5276 - acc: 0.8217 - val_loss: 0.5818 - val_acc: 0.8121
Epoch 17/50
390/390 [==============================] - 20s 52ms/step - loss: 0.5103 - acc: 0.8268 - val_loss: 0.5900 - val_acc: 0.8063
Epoch 18/50
390/390 [==============================] - 21s 53ms/step - loss: 0.5046 - acc: 0.8288 - val_loss: 0.6136 - val_acc: 0.7918
Epoch 19/50
390/390 [==============================] - 21s 53ms/step - loss: 0.4926 - acc: 0.8303 - val_loss: 0.5649 - val_acc: 0.8168
Epoch 20/50
390/390 [==============================] - 20s 52ms/step - loss: 0.4756 - acc: 0.8381 - val_loss: 0.5846 - val_acc: 0.8126
Epoch 21/50
390/390 [==============================] - 21s 53ms/step - loss: 0.4664 - acc: 0.8414 - val_loss: 0.5930 - val_acc: 0.8106
Epoch 22/50
390/390 [==============================] - 21s 53ms/step - loss: 0.4641 - acc: 0.8402 - val_loss: 0.5589 - val_acc: 0.8185
Epoch 23/50
390/390 [==============================] - 21s 53ms/step - loss: 0.4473 - acc: 0.8487 - val_loss: 0.5779 - val_acc: 0.8125
Epoch 24/50
390/390 [==============================] - 21s 53ms/step - loss: 0.4357 - acc: 0.8514 - val_loss: 0.6015 - val_acc: 0.8108
Epoch 25/50
390/390 [==============================] - 20s 53ms/step - loss: 0.4341 - acc: 0.8525 - val_loss: 0.5797 - val_acc: 0.8177
Epoch 26/50
390/390 [==============================] - 21s 55ms/step - loss: 0.4256 - acc: 0.8556 - val_loss: 0.5935 - val_acc: 0.8131
Epoch 27/50
390/390 [==============================] - 21s 54ms/step - loss: 0.4205 - acc: 0.8564 - val_loss: 0.5677 - val_acc: 0.8181
Epoch 28/50
390/390 [==============================] - 21s 53ms/step - loss: 0.4118 - acc: 0.8600 - val_loss: 0.5750 - val_acc: 0.8234
Epoch 29/50
390/390 [==============================] - 21s 54ms/step - loss: 0.4072 - acc: 0.8595 - val_loss: 0.5598 - val_acc: 0.8253
Epoch 30/50
390/390 [==============================] - 21s 54ms/step - loss: 0.4021 - acc: 0.8638 - val_loss: 0.6057 - val_acc: 0.8073
Epoch 31/50
390/390 [==============================] - 21s 54ms/step - loss: 0.4032 - acc: 0.8631 - val_loss: 0.5662 - val_acc: 0.8215
Epoch 32/50
390/390 [==============================] - 21s 54ms/step - loss: 0.3926 - acc: 0.8676 - val_loss: 0.5737 - val_acc: 0.8215
Epoch 33/50
390/390 [==============================] - 21s 54ms/step - loss: 0.3924 - acc: 0.8671 - val_loss: 0.5440 - val_acc: 0.8213
Epoch 34/50
390/390 [==============================] - 21s 54ms/step - loss: 0.3794 - acc: 0.8710 - val_loss: 0.5669 - val_acc: 0.8231
Epoch 35/50
390/390 [==============================] - 21s 53ms/step - loss: 0.3778 - acc: 0.8717 - val_loss: 0.5663 - val_acc: 0.8200
Epoch 36/50
390/390 [==============================] - 21s 54ms/step - loss: 0.3699 - acc: 0.8736 - val_loss: 0.5752 - val_acc: 0.8261
Epoch 37/50
390/390 [==============================] - 21s 54ms/step - loss: 0.3680 - acc: 0.8759 - val_loss: 0.5724 - val_acc: 0.8229
Epoch 38/50
390/390 [==============================] - 21s 54ms/step - loss: 0.3603 - acc: 0.8782 - val_loss: 0.5792 - val_acc: 0.8227
Epoch 39/50
390/390 [==============================] - 21s 54ms/step - loss: 0.3627 - acc: 0.8766 - val_loss: 0.5658 - val_acc: 0.8240
Epoch 40/50
390/390 [==============================] - 21s 54ms/step - loss: 0.3533 - acc: 0.8797 - val_loss: 0.5977 - val_acc: 0.8185
Epoch 41/50
390/390 [==============================] - 21s 54ms/step - loss: 0.3565 - acc: 0.8815 - val_loss: 0.5978 - val_acc: 0.8224
Epoch 42/50
390/390 [==============================] - 21s 54ms/step - loss: 0.3421 - acc: 0.8852 - val_loss: 0.5977 - val_acc: 0.8158
Epoch 43/50
390/390 [==============================] - 21s 53ms/step - loss: 0.3505 - acc: 0.8827 - val_loss: 0.6023 - val_acc: 0.8185
Epoch 44/50
390/390 [==============================] - 21s 54ms/step - loss: 0.3414 - acc: 0.8871 - val_loss: 0.6064 - val_acc: 0.8227
Epoch 45/50
390/390 [==============================] - 21s 54ms/step - loss: 0.3419 - acc: 0.8855 - val_loss: 0.5910 - val_acc: 0.8206
Epoch 46/50
390/390 [==============================] - 21s 54ms/step - loss: 0.3341 - acc: 0.8873 - val_loss: 0.5732 - val_acc: 0.8282
Epoch 47/50
390/390 [==============================] - 21s 54ms/step - loss: 0.3378 - acc: 0.8876 - val_loss: 0.6068 - val_acc: 0.8209
Epoch 48/50
390/390 [==============================] - 21s 54ms/step - loss: 0.3339 - acc: 0.8884 - val_loss: 0.6045 - val_acc: 0.8207
Epoch 49/50
390/390 [==============================] - 21s 53ms/step - loss: 0.3227 - acc: 0.8926 - val_loss: 0.5905 - val_acc: 0.8248
Epoch 50/50
390/390 [==============================] - 21s 54ms/step - loss: 0.3212 - acc: 0.8935 - val_loss: 0.6190 - val_acc: 0.8178
Model took 1050.21 seconds to train

Accuracy on test data is: 81.78


### Results with Depthwise Separtable Convultion

/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.
  if sys.path[0] == '':
/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., validation_data=(array([[[..., callbacks=[<keras.ca..., steps_per_epoch=390, epochs=50)`
  if sys.path[0] == '':
Epoch 1/50
390/390 [==============================] - 43s 110ms/step - loss: 1.2933 - acc: 0.5317 - val_loss: 1.3572 - val_acc: 0.5658

Epoch 00001: val_acc improved from -inf to 0.56580, saving model to weights-improvement-01-0.57.hdf5
Epoch 2/50
390/390 [==============================] - 18s 47ms/step - loss: 0.9029 - acc: 0.6826 - val_loss: 1.0260 - val_acc: 0.6665

Epoch 00002: val_acc improved from 0.56580 to 0.66650, saving model to weights-improvement-02-0.67.hdf5
Epoch 3/50
390/390 [==============================] - 18s 47ms/step - loss: 0.7610 - acc: 0.7349 - val_loss: 0.7759 - val_acc: 0.7225

Epoch 00003: val_acc improved from 0.66650 to 0.72250, saving model to weights-improvement-03-0.72.hdf5
Epoch 4/50
390/390 [==============================] - 18s 46ms/step - loss: 0.6642 - acc: 0.7677 - val_loss: 0.7183 - val_acc: 0.7565

Epoch 00004: val_acc improved from 0.72250 to 0.75650, saving model to weights-improvement-04-0.76.hdf5
Epoch 5/50
390/390 [==============================] - 18s 47ms/step - loss: 0.6023 - acc: 0.7887 - val_loss: 0.6461 - val_acc: 0.7762

Epoch 00005: val_acc improved from 0.75650 to 0.77620, saving model to weights-improvement-05-0.78.hdf5
Epoch 6/50
390/390 [==============================] - 18s 47ms/step - loss: 0.5522 - acc: 0.8080 - val_loss: 0.6706 - val_acc: 0.7705

Epoch 00006: val_acc did not improve from 0.77620
Epoch 7/50
390/390 [==============================] - 18s 47ms/step - loss: 0.5123 - acc: 0.8206 - val_loss: 0.7697 - val_acc: 0.7511

Epoch 00007: val_acc did not improve from 0.77620
Epoch 8/50
390/390 [==============================] - 18s 47ms/step - loss: 0.4802 - acc: 0.8305 - val_loss: 0.6077 - val_acc: 0.7966

Epoch 00008: val_acc improved from 0.77620 to 0.79660, saving model to weights-improvement-08-0.80.hdf5
Epoch 9/50
390/390 [==============================] - 18s 47ms/step - loss: 0.4547 - acc: 0.8399 - val_loss: 0.6722 - val_acc: 0.7798

Epoch 00009: val_acc did not improve from 0.79660
Epoch 10/50
390/390 [==============================] - 18s 47ms/step - loss: 0.4256 - acc: 0.8486 - val_loss: 0.6596 - val_acc: 0.7789

Epoch 00010: val_acc did not improve from 0.79660
Epoch 11/50
390/390 [==============================] - 18s 47ms/step - loss: 0.4044 - acc: 0.8576 - val_loss: 0.6233 - val_acc: 0.8008

Epoch 00011: val_acc improved from 0.79660 to 0.80080, saving model to weights-improvement-11-0.80.hdf5
Epoch 12/50
390/390 [==============================] - 19s 47ms/step - loss: 0.3873 - acc: 0.8638 - val_loss: 0.6980 - val_acc: 0.7835

Epoch 00012: val_acc did not improve from 0.80080
Epoch 13/50
390/390 [==============================] - 18s 47ms/step - loss: 0.3714 - acc: 0.8684 - val_loss: 0.5933 - val_acc: 0.8081

Epoch 00013: val_acc improved from 0.80080 to 0.80810, saving model to weights-improvement-13-0.81.hdf5
Epoch 14/50
390/390 [==============================] - 18s 47ms/step - loss: 0.3558 - acc: 0.8744 - val_loss: 0.6259 - val_acc: 0.8028

Epoch 00014: val_acc did not improve from 0.80810
Epoch 15/50
390/390 [==============================] - 18s 47ms/step - loss: 0.3426 - acc: 0.8799 - val_loss: 0.6282 - val_acc: 0.7999

Epoch 00015: val_acc did not improve from 0.80810
Epoch 16/50
390/390 [==============================] - 18s 47ms/step - loss: 0.3272 - acc: 0.8833 - val_loss: 0.6084 - val_acc: 0.8083

Epoch 00016: val_acc improved from 0.80810 to 0.80830, saving model to weights-improvement-16-0.81.hdf5
Epoch 17/50
390/390 [==============================] - 18s 47ms/step - loss: 0.3173 - acc: 0.8880 - val_loss: 0.6091 - val_acc: 0.8112

Epoch 00017: val_acc improved from 0.80830 to 0.81120, saving model to weights-improvement-17-0.81.hdf5
Epoch 18/50
390/390 [==============================] - 19s 48ms/step - loss: 0.3023 - acc: 0.8931 - val_loss: 0.6200 - val_acc: 0.8063

Epoch 00018: val_acc did not improve from 0.81120
Epoch 19/50
390/390 [==============================] - 18s 47ms/step - loss: 0.2965 - acc: 0.8932 - val_loss: 0.6245 - val_acc: 0.8111

Epoch 00019: val_acc did not improve from 0.81120
Epoch 20/50
390/390 [==============================] - 18s 47ms/step - loss: 0.2900 - acc: 0.8967 - val_loss: 0.6358 - val_acc: 0.8077

Epoch 00020: val_acc did not improve from 0.81120
Epoch 21/50
390/390 [==============================] - 18s 47ms/step - loss: 0.2828 - acc: 0.8980 - val_loss: 0.6439 - val_acc: 0.8051

Epoch 00021: val_acc did not improve from 0.81120
Epoch 22/50
390/390 [==============================] - 18s 47ms/step - loss: 0.2739 - acc: 0.9022 - val_loss: 0.6304 - val_acc: 0.8127

Epoch 00022: val_acc improved from 0.81120 to 0.81270, saving model to weights-improvement-22-0.81.hdf5
Epoch 23/50
390/390 [==============================] - 19s 48ms/step - loss: 0.2644 - acc: 0.9055 - val_loss: 0.6287 - val_acc: 0.8110

Epoch 00023: val_acc did not improve from 0.81270
Epoch 24/50
390/390 [==============================] - 18s 47ms/step - loss: 0.2606 - acc: 0.9054 - val_loss: 0.6564 - val_acc: 0.8059

Epoch 00024: val_acc did not improve from 0.81270
Epoch 25/50
390/390 [==============================] - 18s 47ms/step - loss: 0.2580 - acc: 0.9067 - val_loss: 0.6333 - val_acc: 0.8165

Epoch 00025: val_acc improved from 0.81270 to 0.81650, saving model to weights-improvement-25-0.82.hdf5
Epoch 26/50
390/390 [==============================] - 18s 47ms/step - loss: 0.2507 - acc: 0.9103 - val_loss: 0.6457 - val_acc: 0.8117

Epoch 00026: val_acc did not improve from 0.81650
Epoch 27/50
390/390 [==============================] - 18s 47ms/step - loss: 0.2414 - acc: 0.9128 - val_loss: 0.6523 - val_acc: 0.8092

Epoch 00027: val_acc did not improve from 0.81650
Epoch 28/50
390/390 [==============================] - 18s 47ms/step - loss: 0.2396 - acc: 0.9123 - val_loss: 0.6791 - val_acc: 0.8096

Epoch 00028: val_acc did not improve from 0.81650
Epoch 29/50
390/390 [==============================] - 18s 47ms/step - loss: 0.2337 - acc: 0.9146 - val_loss: 0.6901 - val_acc: 0.8054

Epoch 00029: val_acc did not improve from 0.81650
Epoch 30/50
390/390 [==============================] - 18s 47ms/step - loss: 0.2275 - acc: 0.9182 - val_loss: 0.6591 - val_acc: 0.8127

Epoch 00030: val_acc did not improve from 0.81650
Epoch 31/50
390/390 [==============================] - 18s 47ms/step - loss: 0.2257 - acc: 0.9193 - val_loss: 0.6738 - val_acc: 0.8118

Epoch 00031: val_acc did not improve from 0.81650
Epoch 32/50
390/390 [==============================] - 18s 47ms/step - loss: 0.2214 - acc: 0.9193 - val_loss: 0.6680 - val_acc: 0.8141

Epoch 00032: val_acc did not improve from 0.81650
Epoch 33/50
390/390 [==============================] - 18s 47ms/step - loss: 0.2187 - acc: 0.9207 - val_loss: 0.6832 - val_acc: 0.8127

Epoch 00033: val_acc did not improve from 0.81650
Epoch 34/50
390/390 [==============================] - 18s 47ms/step - loss: 0.2186 - acc: 0.9201 - val_loss: 0.6645 - val_acc: 0.8142

Epoch 00034: val_acc did not improve from 0.81650
Epoch 35/50
390/390 [==============================] - 19s 48ms/step - loss: 0.2082 - acc: 0.9243 - val_loss: 0.6794 - val_acc: 0.8131

Epoch 00035: val_acc did not improve from 0.81650
Epoch 36/50
390/390 [==============================] - 18s 47ms/step - loss: 0.2092 - acc: 0.9240 - val_loss: 0.6825 - val_acc: 0.8128

Epoch 00036: val_acc did not improve from 0.81650
Epoch 37/50
390/390 [==============================] - 19s 48ms/step - loss: 0.2011 - acc: 0.9272 - val_loss: 0.6973 - val_acc: 0.8089

Epoch 00037: val_acc did not improve from 0.81650
Epoch 38/50
390/390 [==============================] - 19s 48ms/step - loss: 0.2023 - acc: 0.9271 - val_loss: 0.6924 - val_acc: 0.8128

Epoch 00038: val_acc did not improve from 0.81650
Epoch 39/50
390/390 [==============================] - 19s 48ms/step - loss: 0.1990 - acc: 0.9264 - val_loss: 0.6911 - val_acc: 0.8132

Epoch 00039: val_acc did not improve from 0.81650
Epoch 40/50
390/390 [==============================] - 19s 47ms/step - loss: 0.1958 - acc: 0.9299 - val_loss: 0.7009 - val_acc: 0.8120

Epoch 00040: val_acc did not improve from 0.81650
Epoch 41/50
390/390 [==============================] - 19s 48ms/step - loss: 0.1912 - acc: 0.9299 - val_loss: 0.7058 - val_acc: 0.8118

Epoch 00041: val_acc did not improve from 0.81650
Epoch 42/50
390/390 [==============================] - 19s 48ms/step - loss: 0.1904 - acc: 0.9303 - val_loss: 0.7107 - val_acc: 0.8128

Epoch 00042: val_acc did not improve from 0.81650
Epoch 43/50
390/390 [==============================] - 19s 48ms/step - loss: 0.1902 - acc: 0.9307 - val_loss: 0.7140 - val_acc: 0.8105

Epoch 00043: val_acc did not improve from 0.81650
Epoch 44/50
390/390 [==============================] - 19s 48ms/step - loss: 0.1873 - acc: 0.9302 - val_loss: 0.6978 - val_acc: 0.8147

Epoch 00044: val_acc did not improve from 0.81650
Epoch 45/50
390/390 [==============================] - 19s 48ms/step - loss: 0.1869 - acc: 0.9317 - val_loss: 0.7227 - val_acc: 0.8143

Epoch 00045: val_acc did not improve from 0.81650
Epoch 46/50
390/390 [==============================] - 19s 48ms/step - loss: 0.1805 - acc: 0.9343 - val_loss: 0.7299 - val_acc: 0.8096

Epoch 00046: val_acc did not improve from 0.81650
Epoch 47/50
390/390 [==============================] - 19s 48ms/step - loss: 0.1801 - acc: 0.9337 - val_loss: 0.7167 - val_acc: 0.8127

Epoch 00047: val_acc did not improve from 0.81650
Epoch 48/50
390/390 [==============================] - 19s 48ms/step - loss: 0.1797 - acc: 0.9333 - val_loss: 0.7224 - val_acc: 0.8154

Epoch 00048: val_acc did not improve from 0.81650
Epoch 49/50
390/390 [==============================] - 19s 48ms/step - loss: 0.1744 - acc: 0.9354 - val_loss: 0.7392 - val_acc: 0.8145

Epoch 00049: val_acc did not improve from 0.81650
Epoch 50/50
390/390 [==============================] - 19s 48ms/step - loss: 0.1750 - acc: 0.9370 - val_loss: 0.7384 - val_acc: 0.8135

Epoch 00050: val_acc did not improve from 0.81650
Model took 986.16 seconds to train

Accuracy on test data is: 81.35

dropout_rate = 0.1
model1 = Sequential()

model1.add(SeparableConv2D(32, (3, 3), input_shape=(32, 32, 3), padding='same',strides=1)) # output channel size: 32 receptive field: 3
model1.add(Activation('relu'))
model1.add(BatchNormalization())
model1.add(Dropout(dropout_rate))


model1.add(SeparableConv2D(64, (3, 3), padding='same')) # output channel size: 32 receptive field: 5
model1.add(Activation('relu'))
model1.add(BatchNormalization())
model1.add(Dropout(dropout_rate))


model1.add(SeparableConv2D(128, (3, 3),padding='same')) # output channel size: 32 receptive field: 7
model1.add(Activation('relu'))
model1.add(BatchNormalization())
model1.add(Dropout(0.2))

#layer 3
model1.add(SeparableConv2D(32, (1, 1))) # output channel size: 16 receptive field: 8
model1.add(Activation('relu'))
model1.add(MaxPooling2D(pool_size=(2,2))) #output channel size:16

model1.add(SeparableConv2D(64, (3, 3),padding='same')) # output channel size: 16 receptive field: 12
model1.add(Activation('relu'))
model1.add(BatchNormalization())
model1.add(Dropout(0.2))

model1.add(SeparableConv2D(128, (3, 3))) # output channel size: 12 receptive field: 16
model1.add(Activation('relu'))
model1.add(BatchNormalization())
model1.add(Dropout(dropout_rate))

model1.add(SeparableConv2D(256, (3, 3))) # output channel size: 10 receptive field: 20
model1.add(Activation('relu'))


model1.add(SeparableConv2D(10, (10, 10))) # output channel size: 10 receptive field: 24
model1.add(GlobalAveragePooling2D())
model1.add(Activation('softmax'))
model1.summary()
